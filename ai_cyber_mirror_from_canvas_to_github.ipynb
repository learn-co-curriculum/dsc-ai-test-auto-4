{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import markdown\n",
    "import markdown2\n",
    "import re \n",
    "\n",
    "from canvasapi import Canvas\n",
    "\n",
    "from canvas_to_git import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Canvas API\n",
    "\n",
    "\n",
    "Add Canvas credentials. \n",
    "\n",
    "* The API key should be stored in your `.env` file.\n",
    "* Change to the relevant Canvas instance as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_api_key = os.environ.get('CANVAS_TOKEN')\n",
    "canvas_instance = \"https://learning.flatironschool.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to Canvas API by creating a Canvas instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = Canvas(canvas_instance, canvas_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Locate Course\n",
    "For all of the methods available for the Course class, see [the Course documentation](https://canvasapi.readthedocs.io/en/stable/course-ref.html#course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To work with an existing course, input a course number.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_number = 6996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP: AI Course - AI & Cybersecurity\n"
     ]
    }
   ],
   "source": [
    "course = canvas.get_course(course_number)\n",
    "print(course.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Content\n",
    "\n",
    "First get the course pages from Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = course.get_pages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use lists to gather the relevant page IDs, page contents, titles, and URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "page_ids = []\n",
    "urls = []\n",
    "contents = []\n",
    "\n",
    "for page in content:\n",
    "    pid = page.page_id\n",
    "    page_ids += [pid]\n",
    "    p = course.get_page(pid)\n",
    "    titles += [p.title]\n",
    "    urls += [p.url]\n",
    "    contents += [p.body]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, extract the titles of lessons and labs only, ignoring any housekeeping/admin pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['üìö Reading: Introduction- AI/ML Systems for Malicious Activities',\n",
       " '1Ô∏è‚É£ Module 1 Overview',\n",
       " '2Ô∏è‚É£ Module 2 Overview',\n",
       " '3Ô∏è‚É£ Module 3 Overview',\n",
       " ' \\xa04Ô∏è‚É£ Module 4 Overview',\n",
       " 'üîé Lab: 2.4 HAM or PHISH? - NLP for Email Filtering ',\n",
       " 'üîé Lab: Best Practices for Securing and Safely Deploying AI/ML Systems',\n",
       " 'üîé Lab: Machine Learning for Situational Intelligence',\n",
       " 'üîö Module 1 Conclusion',\n",
       " 'üîö Module 2 Conclusion ',\n",
       " 'üîö Module 3 Conclusion  ',\n",
       " 'üîö Module 4 Conclusion   ',\n",
       " 'üìö Reading: AI/ML Systems for Malicious Activities - DeepLocker',\n",
       " 'üìö Reading: Benefits and Challenges of AI Threat Intelligence',\n",
       " 'üìö Reading: Best Practices for Secure and Safe Deployment of AI/ML Systems',\n",
       " 'üìö Reading: Feature Engineering and Model Evaluation',\n",
       " 'üìö Reading: Introduction to AI/ML Systems for Malicious Activities',\n",
       " 'üìö Reading: Introduction to AI Threat Detection',\n",
       " 'üìö Reading: Learning Algorithms in Cyber Security: Supervised versus Unsupervised',\n",
       " 'üìö Reading: Machine Learning Fundamentals for Cyber Security',\n",
       " 'üìö Reading: Natural Language Processing (NLP) for Cyber Security',\n",
       " 'üìö Reading: NLP for Phishing Email Analysis',\n",
       " 'üìö Reading: NLP Techniques in Cybersecurity',\n",
       " 'üìö Reading: Real-World Examples of Applied AI-Based Threat Intelligence',\n",
       " 'Home Page',\n",
       " '‚≠êÔ∏è Instructor Guide (Do Not Publish)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_content = list(zip(titles, page_ids, urls, contents))\n",
    "\n",
    "# I am using list comprehension here to filter my titles, but, you may want to use another method.\n",
    "adj_titles = [title for title in zipped_content \n",
    "                if title[0].startswith('üìö Reading:')\n",
    "                 or title[0].startswith('üîé Lab:')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('üìö Reading: Introduction- AI/ML Systems for Malicious Activities',\n",
       " 267201,\n",
       " 'reading-introduction-ai-slash-ml-systems-for-malicious-activities',\n",
       " '<p><em>Select the tabs to navigate through the content.</em></p>\\n<div style=\"margin: 1em 0%; padding: 10px 15px; border: 2px solid #A2AAAD; background: #ffffff; font-size: 100%; overflow: auto;\">\\n<div class=\"enhanceable_content tabs\">\\n<ul>\\n<li><a href=\"#fragment-1\">Introduction</a></li>\\n<li><a href=\"#fragment-2\">How do Threat Actors Misuse AI/ML</a></li>\\n<li><a href=\"#fragment-3\">Summary</a></li>\\n<li><a href=\"#fragment-4\">Check For Understanding</a></li>\\n</ul>\\n<div id=\"fragment-1\" style=\"overflow: auto:;\">\\n<h3>Introduction</h3>\\n<p>In recent years, threat actors have recognized the immense potential of artificial intelligence (AI) and machine learning (ML) in their malicious activities. They have swiftly adapted to these technologies, leveraging them to enhance their attack capabilities and stay one step ahead of traditional security measures. This emerging trend poses a significant challenge for organizations and security professionals who must understand how threat actors employ AI/ML to develop effective countermeasures.</p>\\n<p>By harnessing the power of AI and ML, threat actors can automate and optimize their attack strategies, making their campaigns more sophisticated and evasive. Adversarial attacks, for instance, enable them to manipulate AI algorithms, bypass security measures, and deceive AI-based systems, compromising their reliability and effectiveness. Additionally, attackers can leverage ML algorithms to automatically generate variants of malware that can evade traditional signature-based detection methods, increasing the difficulty of identifying and mitigating threats.</p>\\n<p>Understanding AI/ML and how threat actors exploit these technologies is paramount for developing robust countermeasures. Security professionals need to stay updated on the latest advancements and techniques employed by malicious actors. This knowledge empowers them to detect and mitigate emerging threats effectively, ensuring the security and integrity of their systems and data. Moreover, organizations must invest in research and development to build AI-driven defense mechanisms capable of combating the evolving threat landscape.&nbsp;</p>\\n<p>In this lesson, we identify some common attacker behaviors and patterns, that security teams can leverage AI/ML to proactively identify anomalies, detect sophisticated attacks, and respond swiftly to mitigate potential risks.</p>\\n<h4>Lesson Objectives</h4>\\n<p>By the end of this lesson you will be able to&nbsp;</p>\\n<ul>\\n<li>List reading/lesson objectives&nbsp;</li>\\n</ul>\\n</div>\\n<div id=\"fragment-2\" style=\"overflow: auto:;\">\\n<h3>How do Threat Actors Misuse AI/ML</h3>\\n<p>As artificial intelligence (AI) and machine learning (ML) systems become more powerful, it is important to be aware of the potential for malicious use. &nbsp;Organizations need to take steps to secure their AI and ML systems and to protect themselves from attack.</p>\\n<p>These are some of the ways that AI and ML can be misused by threat actors.</p>\\n<h4>1. Adversarial Attacks</h4>\\n<ul>\\n<li>Threat actors can use AI to launch adversarial attacks against AI systems. &nbsp;By manipulating or deceiving AI algorithms, attackers can bypass security measures, generate false positives or negatives, or evade detection.</li>\\n<li>Adversarial attacks aim to exploit vulnerabilities in AI models and undermine the reliability and effectiveness of AI-based threat detection systems.</li>\\n</ul>\\n<h4>2. Evasion of Security Measures</h4>\\n<ul>\\n<li>AI and ML can be used to analyze and understand the inner workings of security systems, enabling threat actors to develop sophisticated evasion techniques.</li>\\n<li>By leveraging ML algorithms, attackers can automatically generate variants of malware that can evade traditional signature-based detection methods, making it more difficult for security solutions to identify and mitigate threats.</li>\\n</ul>\\n<h4>3. Automated Exploitation&nbsp;</h4>\\n<ul>\\n<li>Threat actors can leverage AI and ML to automate and enhance their attack capabilities.&nbsp;</li>\\n<li>Machine learning algorithms can be trained to identify vulnerabilities in systems, networks, or applications, making it easier for attackers to exploit these weaknesses at scale. &nbsp;</li>\\n<li>Automated attacks powered by AI can launch targeted and persistent campaigns against vulnerable targets, increasing the efficiency and impact of cyber attacks.</li>\\n</ul>\\n<h4>4. Social Engineering and Phishing Attacks</h4>\\n<ul>\\n<li>AI techniques can be utilized to enhance social engineering and phishing attacks.</li>\\n<li>Attackers can leverage machine learning algorithms to analyze large amounts of data to create highly personalized and convincing phishing emails, messages, or voice calls. &nbsp;</li>\\n<li>By leveraging AI, threat actors can craft messages that are more likely to deceive recipients, increasing the success rate of their phishing campaigns.</li>\\n</ul>\\n<h4>5. Data Poisoning and Manipulation</h4>\\n<ul>\\n<li>AI models rely on data for training and decision-making. &nbsp;</li>\\n<li>Threat actors can exploit this vulnerability by poisoning or manipulating training data to introduce biases or make the AI models produce erroneous results.</li>\\n<li>By strategically injecting malicious data during the training phase, attackers can deceive AI systems, leading to incorrect decisions or actions taken by the systems.</li>\\n</ul>\\n<h4>6. Automated Reconnaissance</h4>\\n<ul>\\n<li>AI can be utilized for automated reconnaissance and information gathering. &nbsp;</li>\\n<li>Threat actors can employ ML algorithms to analyze vast amounts of publicly available data, social media profiles, or network traffic patterns to identify potential targets, vulnerabilities, or weak points in a target organization\\'s security posture. &nbsp;This information can then be used to plan and execute targeted attacks.</li>\\n</ul>\\n<h4>7. Weaponized AI</h4>\\n<ul>\\n<li>Advanced AI techniques can be used to develop sophisticated and autonomous cyber weapons. &nbsp;These AI-driven weapons can adapt, evolve, and learn from their environment to optimize their attack strategies. &nbsp;</li>\\n<li>AI-powered cyber weapons can pose significant threats by conducting large-scale attacks, exploiting vulnerabilities, or evading traditional defenses.</li>\\n</ul>\\n</div>\\n<div id=\"fragment-3\" style=\"overflow: auto:;\">\\n<h3>Summary</h3>\\n<p>In this lesson, we introduced the topic AI/ML systems for malicious activities. We identified numerous ways that cyber criminals can use AI to enhance their ability to evade detection. While the availability of exploits is vast, there are a number of counter measures that you can take to protect yourself and your organization from cyber attacks that we will review in the upcoming lesson.</p>\\n<p>It is essential for cybersecurity professionals to engage in continuous learning and collaboration to share insights, exchange best practices, and collectively develop strategies to combat AI-enhanced cyber threats. By fostering a comprehensive understanding of AI/ML and threat actor tactics, we can build a resilient cybersecurity ecosystem that safeguards our digital assets and protects against emerging threats in the ever-evolving landscape of cybercrime.</p>\\n</div>\\n<div id=\"fragment-4\" style=\"overflow: auto:;\">\\n<h3>Check For Understanding</h3>\\n<p>In this section you will be able to quiz yourself on the key takeaways from the readings. These questions will help prepare you for the other assessments in the module.&nbsp;</p>\\n<p><em>Select the question to view the answer.</em></p>\\n<details>\\n<summary style=\"padding: 15px; font-size: 150%; border: 2px solid #A2AAAD;\"><strong>True or False:</strong> Adversarial attacks aim to strengthen the reliability and effectiveness of AI-based threat detection systems.</summary>\\n<p style=\"margin-left: 10px;\"><strong>False</strong>, adversarial attacks aim to exploit vulnerabilities in AI models and undermine the reliability and effectiveness of AI-based threat detection systems.</p>\\n</details><details>\\n<summary style=\"padding: 15px; font-size: 150%; border: 2px solid #A2AAAD;\"><strong>True or False:</strong> By leveraging machine learning algorithms, attackers can automatically generate variants of malware that can evade traditional signature-based detection methods.</summary>\\n<p style=\"margin-left: 10px;\"><strong>True</strong>, machine learning algorithms can be trained to identify vulnerabilities in systems, networks, or applications, making it easier for attackers to exploit these weaknesses at scale.</p>\\n</details><details>\\n<summary style=\"padding: 15px; font-size: 150%; border: 2px solid #A2AAAD;\"><strong>True or False:</strong>Threat actors can utilize AI techniques to enhance social engineering and phishing attacks, increasing the success rate of their campaigns.</summary>\\n<p style=\"margin-left: 10px;\"><strong>True</strong>, AI techniques can be utilized to enhance social engineering and phishing attacks.&nbsp;</p>\\n</details></div>\\n</div>\\n</div>')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "adj_titles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mirror Canvas Lessons to GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to create the repo for the first time. \n",
    "\n",
    "**Change this cell to your course prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'ai-course-cyber-'\n",
    "org_name = 'learn-co-curriculum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai-course-cyber-reading-introduction-ai-slash-ml-systems-for-malicious-activities\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-lab-2-dot-4-ham-or-phish-nlp-for-email-filtering\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-lab-best-practices-for-securing-and-safely-deploying-ai-slash-ml-systems\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-lab-machine-learning-for-situational-intelligence\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-ai-slash-ml-systems-for-malicious-activities-deeplocker\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-benefits-and-challenges-of-ai-threat-intelligence\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-best-practices-for-secure-and-safe-deployment-of-ai-slash-ml-systems\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-feature-engineering-and-model-evaluation\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-introduction-to-ai-slash-ml-systems-for-malicious-activities\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-introduction-to-ai-threat-detection\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-learning-algorithms-in-cyber-security-supervised-versus-unsupervised\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-machine-learning-fundamentals-for-cyber-security\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-natural-language-processing-nlp-for-cyber-security\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-nlp-for-phishing-email-analysis\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-nlp-techniques-in-cybersecurity\n",
      "File created/updated successfully!\n",
      "ai-course-cyber-reading-real-world-examples-of-applied-ai-based-threat-intelligence\n",
      "File created/updated successfully!\n"
     ]
    }
   ],
   "source": [
    "for title in adj_titles:\n",
    "    repository_name = f'{prefix}{title[2]}'\n",
    "    organization_name = org_name\n",
    "    print(repository_name)\n",
    "    \n",
    "    ## I only need to run the line below the first time the repo is created.\n",
    "    ## Comment it out during updates\n",
    "    # create_github_repository(repository_name, organization_name)\n",
    "\n",
    "    content = title[3]\n",
    "    file_path = 'README.md'\n",
    "    file_title = title[0]\n",
    "    file_content = f'# {file_title}\\n\\n{content}'  # Updated content of the file\n",
    "    commit_message = 'Update file'  # Commit message for the file operation\n",
    "    create_or_update_file(repository_name, organization_name, file_path, file_content, commit_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 (spacy)",
   "language": "python",
   "name": "venv_spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
